{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Seq2seq+attention+coverage+embedding+beam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "49beebd721e3417ca0ed1efcdad3a73c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a0887b2d69444f76ab43866b9fadfc52",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4dea8893e65f409ab475a547ce4fc63d",
              "IPY_MODEL_35ef93f265494c92ae1f288030ddc372"
            ]
          }
        },
        "a0887b2d69444f76ab43866b9fadfc52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4dea8893e65f409ab475a547ce4fc63d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e6360e3db831469bbe78e30c7b52227d",
            "_dom_classes": [],
            "description": "Epoch 5",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42730b402ca64cc7b02d578e0af05662"
          }
        },
        "35ef93f265494c92ae1f288030ddc372": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_35c18a134a4440fbab9c06dec4c52772",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 5/5 [40:45&lt;00:00, 485.49s/it, Loss=2.82]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ceb40ea7c4904379b0f4ab928fabbf24"
          }
        },
        "e6360e3db831469bbe78e30c7b52227d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42730b402ca64cc7b02d578e0af05662": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35c18a134a4440fbab9c06dec4c52772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ceb40ea7c4904379b0f4ab928fabbf24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "222ebdfa9e35453aba6e2d23c447a1b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7b4cb2751bb64f45b17cda954c88bbed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4c6fb04b5adf4c58b7afcdf6c504ea62",
              "IPY_MODEL_df604f8a21c84ac8b2d23ccb88ee5878"
            ]
          }
        },
        "7b4cb2751bb64f45b17cda954c88bbed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c6fb04b5adf4c58b7afcdf6c504ea62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_954926dec0864ab7b0e868a6c221763d",
            "_dom_classes": [],
            "description": "Epoch 1",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 427,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 427,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29a15376ad4f4f40bf7a975dd40af382"
          }
        },
        "df604f8a21c84ac8b2d23ccb88ee5878": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0049272fffa544d7bb2a7f65b2b1f368",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 427/427 [08:20&lt;00:00,  1.14s/it, Batch=420, Loss=3.67]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a27cbc71c5564edab2ccd458eff6ee55"
          }
        },
        "954926dec0864ab7b0e868a6c221763d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29a15376ad4f4f40bf7a975dd40af382": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0049272fffa544d7bb2a7f65b2b1f368": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a27cbc71c5564edab2ccd458eff6ee55": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1456ba6aae744287a0397e183bed7ece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6599d11db78749cca023e1f2ac1f48a5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_74261db027f141bdb5619c5a0dfc2a3f",
              "IPY_MODEL_0dc84f675f2a4f3fa8ef28068d81a302"
            ]
          }
        },
        "6599d11db78749cca023e1f2ac1f48a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "74261db027f141bdb5619c5a0dfc2a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1c33a01277e748ff9c917cc306a13cbb",
            "_dom_classes": [],
            "description": "Epoch 2",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 427,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 427,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7adaf5b1c09544f09e04a532d2c45a89"
          }
        },
        "0dc84f675f2a4f3fa8ef28068d81a302": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_491f030c8f6c48eba645e477969f0981",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 427/427 [08:18&lt;00:00,  1.18s/it, Batch=420, Loss=3.75]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f1e4894ad8c487e815ab336f1747fc8"
          }
        },
        "1c33a01277e748ff9c917cc306a13cbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7adaf5b1c09544f09e04a532d2c45a89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "491f030c8f6c48eba645e477969f0981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f1e4894ad8c487e815ab336f1747fc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db6e4e341e9243828bb750db067bb681": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d5209897a55549e7903b313148b0a01d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_060eec12dc7044b9b405adeebfcf154b",
              "IPY_MODEL_e13bb4b7823a4dc0bc291913866fbaaa"
            ]
          }
        },
        "d5209897a55549e7903b313148b0a01d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "060eec12dc7044b9b405adeebfcf154b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_50f0486fdaef49e7800fd45aa3d39882",
            "_dom_classes": [],
            "description": "Epoch 3",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 427,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 427,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c1a03e7502a4fdf8a8f33505ef34bcd"
          }
        },
        "e13bb4b7823a4dc0bc291913866fbaaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8fee3ab5cc148679a2d894e1a7bbb39",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 427/427 [08:17&lt;00:00,  1.14s/it, Batch=420, Loss=2.96]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0ac14d8b93d479894e06c13bb342776"
          }
        },
        "50f0486fdaef49e7800fd45aa3d39882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c1a03e7502a4fdf8a8f33505ef34bcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8fee3ab5cc148679a2d894e1a7bbb39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0ac14d8b93d479894e06c13bb342776": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b06a062dcc6d414c8111cdf8f7bbaa4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1adfa4776e93499ea63346a33a6c1481",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4057ebcc415244e084af1fd16a5b9ffc",
              "IPY_MODEL_55b400f46a594318af33cbec9ba93cd3"
            ]
          }
        },
        "1adfa4776e93499ea63346a33a6c1481": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4057ebcc415244e084af1fd16a5b9ffc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4b43d9adc04847698bd21363ed84e165",
            "_dom_classes": [],
            "description": "Epoch 4",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 427,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 427,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1bf768ab12b49439255ea2b0e0ef6e9"
          }
        },
        "55b400f46a594318af33cbec9ba93cd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_972f114dc0214127a250853d4ba73ef3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 427/427 [08:05&lt;00:00,  1.11s/it, Batch=420, Loss=2.99]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24ad41d2518e4287970b159f83c9cb71"
          }
        },
        "4b43d9adc04847698bd21363ed84e165": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1bf768ab12b49439255ea2b0e0ef6e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "972f114dc0214127a250853d4ba73ef3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24ad41d2518e4287970b159f83c9cb71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5411c13cbc043b8a7eb606a92ee8058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_50259c9b525d4fe28c95b3abbd43d48d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9428fd4bd0ca457aa83af938b7bfe107",
              "IPY_MODEL_d7ef96b8fb674acda91e765f87eb15c6"
            ]
          }
        },
        "50259c9b525d4fe28c95b3abbd43d48d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9428fd4bd0ca457aa83af938b7bfe107": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2b6090dbebe24682bcec05fc6b270339",
            "_dom_classes": [],
            "description": "Epoch 5",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 427,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 427,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6481a40e13e4486689f4138121635be3"
          }
        },
        "d7ef96b8fb674acda91e765f87eb15c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_15684a1d52c24a62bb053f04495b4b2c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 427/427 [07:43&lt;00:00,  1.07s/it, Batch=420, Loss=2.98]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_52d386ee5b994b49aa092eeb0a0b22c0"
          }
        },
        "2b6090dbebe24682bcec05fc6b270339": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6481a40e13e4486689f4138121635be3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "15684a1d52c24a62bb053f04495b4b2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "52d386ee5b994b49aa092eeb0a0b22c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6YcmNYRS2XN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq85hhsbhYug",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import files\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XFPMTnOV7rV",
        "colab_type": "text"
      },
      "source": [
        "Load the text files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iSTmwbxS7cJ",
        "colab_type": "code",
        "outputId": "3f119c9e-f4f2-42a0-c078-9bac3805d7a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "if not os.path.exists('tok.valid.abstract.txt'):\n",
        "  !wget -O 'tok.valid.abstract.txt' 'https://www.dropbox.com/s/0c6e9yf8yhf9a75/tok.valid.abstract.txt?dl=1'\n",
        "if not os.path.exists('tok.valid.body.txt'):\n",
        "  !wget -O 'tok.valid.title.txt' 'https://www.dropbox.com/s/aiy87847kusb7ju/tok.valid.title.txt?dl=1'"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-12-05 00:54:50--  https://www.dropbox.com/s/aiy87847kusb7ju/tok.valid.title.txt?dl=1\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.1, 2620:100:6032:1::a27d:5201\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/dl/aiy87847kusb7ju/tok.valid.title.txt [following]\n",
            "--2019-12-05 00:54:50--  https://www.dropbox.com/s/dl/aiy87847kusb7ju/tok.valid.title.txt\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uca165cc84be1d4b2bcd0d0cf3b3.dl.dropboxusercontent.com/cd/0/get/AtqtoFzceoFyyeND2LRWiEQQ7mo1ZIuqd8T6Wu3_i-KxIe8V-X0DLVPCfd05pvvoV6QU41-4a-26LNS8pDP9VunAAfZyYfOipvcihLUC9UrsC4CG05CdsdNL_PIIUb_Dl7w/file?dl=1# [following]\n",
            "--2019-12-05 00:54:51--  https://uca165cc84be1d4b2bcd0d0cf3b3.dl.dropboxusercontent.com/cd/0/get/AtqtoFzceoFyyeND2LRWiEQQ7mo1ZIuqd8T6Wu3_i-KxIe8V-X0DLVPCfd05pvvoV6QU41-4a-26LNS8pDP9VunAAfZyYfOipvcihLUC9UrsC4CG05CdsdNL_PIIUb_Dl7w/file?dl=1\n",
            "Resolving uca165cc84be1d4b2bcd0d0cf3b3.dl.dropboxusercontent.com (uca165cc84be1d4b2bcd0d0cf3b3.dl.dropboxusercontent.com)... 162.125.82.6, 2620:100:6032:6::a27d:5206\n",
            "Connecting to uca165cc84be1d4b2bcd0d0cf3b3.dl.dropboxusercontent.com (uca165cc84be1d4b2bcd0d0cf3b3.dl.dropboxusercontent.com)|162.125.82.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 711754 (695K) [application/binary]\n",
            "Saving to: ‘tok.valid.title.txt’\n",
            "\n",
            "\rtok.valid.title.txt   0%[                    ]       0  --.-KB/s               \rtok.valid.title.txt   5%[>                   ]  39.30K   164KB/s               \rtok.valid.title.txt  12%[=>                  ]  87.30K   190KB/s               \rtok.valid.title.txt  26%[====>               ] 183.30K   276KB/s               \rtok.valid.title.txt  42%[=======>            ] 295.30K   301KB/s               \rtok.valid.title.txt  56%[==========>         ] 391.30K   329KB/s               \rtok.valid.title.txt  70%[=============>      ] 487.30K   350KB/s               \rtok.valid.title.txt  83%[===============>    ] 583.30K   365KB/s               \rtok.valid.title.txt  95%[==================> ] 663.30K   342KB/s               \rtok.valid.title.txt 100%[===================>] 695.07K   357KB/s    in 1.9s    \n",
            "\n",
            "2019-12-05 00:54:54 (357 KB/s) - ‘tok.valid.title.txt’ saved [711754/711754]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZGjRsj3TdyM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('tok.valid.abstract.txt','rb') as f:\n",
        "    body_data = f.read().decode(\"utf-8\").split('\\n')\n",
        "    \n",
        "with open('tok.valid.title.txt','rb') as f:\n",
        "    target_data = f.read().decode(\"utf-8\").split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tZMq4lCWA5x",
        "colab_type": "text"
      },
      "source": [
        "Create vocabulary using keras tokenizer "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRFn7JpiUc6l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 20000\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size, oov_token='<UNK>')\n",
        "tokenizer.fit_on_texts(body_data)\n",
        "tokenizer.index_word[vocab_size] = '<s>'\n",
        "tokenizer.index_word[vocab_size+1] = '<\\s>'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxBcIPC-p6rJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Vocab(object):\n",
        "  def __init__(self, max_size):\n",
        "    self._word_to_id = {}\n",
        "    self._id_to_word = {}\n",
        "    self._count = 0 # keeps track of total number of words in the Vocab\n",
        "    self._word_to_id['<PAD>'] = self._count\n",
        "    self._id_to_word[self._count] = '<PAD>'\n",
        "    self._count += 1\n",
        "    for _, word in tokenizer.index_word.items():\n",
        "      self._word_to_id[word] = self._count\n",
        "      self._id_to_word[self._count] = word\n",
        "      self._count += 1\n",
        "      if max_size != 0 and self._count >= max_size:\n",
        "        break\n",
        "    print(\"Finished constructing vocabulary of %i total words. Last word added: %s\" % (self._count, self._id_to_word[self._count-1]))\n",
        "  def word2id(self, word):\n",
        "    \"\"\"Returns the id (integer) of a word (string). Returns [UNK] id if word is OOV.\"\"\"\n",
        "    if word not in self._word_to_id:\n",
        "      return self._word_to_id['<UNK>']\n",
        "    return self._word_to_id[word]\n",
        "\n",
        "  def id2word(self, word_id):\n",
        "    \"\"\"Returns the word (string) corresponding to an id (integer).\"\"\"\n",
        "    if word_id not in self._id_to_word:\n",
        "      raise ValueError('Id not found in vocab: %d' % word_id)\n",
        "    return self._id_to_word[word_id]\n",
        "\n",
        "  def size(self):\n",
        "    \"\"\"Returns the total size of the vocabulary\"\"\"\n",
        "    return self._count"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1a8Z8pBttgo",
        "colab_type": "code",
        "outputId": "4f2f7ea7-166b-4818-ad65-d7fdde87d024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocab = Vocab(vocab_size+2)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Finished constructing vocabulary of 20002 total words. Last word added: <\\s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wSPsQ34uTBn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def source2ids(source_words):\n",
        "  \"\"\"Map the source words to their ids and return a list of OOVs in the source.\n",
        "  Args:\n",
        "    source_words: list of words (strings)\n",
        "    vocab: Vocabulary object\n",
        "  Returns:\n",
        "    ids:\n",
        "      A list of word ids (integers); OOVs are represented by their temporary article OOV number. If the vocabulary size is 50k and the article has 3 OOVs, then these temporary OOV numbers will be 50000, 50001, 50002.\n",
        "    oovs:\n",
        "      A list of the OOV words in the article (strings), in the order corresponding to their temporary article OOV numbers.\"\"\"\n",
        "  ids = []\n",
        "  oovs = []\n",
        "  unk_id = vocab.word2id(\"<UNK>\")\n",
        "  for w in source_words.split(\" \"):\n",
        "    i = vocab.word2id(w)\n",
        "    if i == unk_id: # If w is OOV\n",
        "      if w not in oovs: # Add to list of OOVs\n",
        "        oovs.append(w)\n",
        "      oov_num = oovs.index(w) # This is 0 for the first source OOV, 1 for the second source OOV...\n",
        "      ids.append(vocab.size() + oov_num) # This is e.g. 20000 for the first source OOV, 50001 for the second...\n",
        "    else:\n",
        "      ids.append(i)\n",
        "  return ids, oovs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9tQmTwx5o1m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def outputids2words(id_list, source_oovs):\n",
        "  \"\"\"Maps output ids to words, including mapping in-article OOVs from their temporary ids to the original OOV string (applicable in pointer-generator mode).\n",
        "  Args:\n",
        "    id_list: list of ids (integers)\n",
        "    vocab: Vocabulary object\n",
        "    article_oovs: list of OOV words (strings) in the order corresponding to their temporary article OOV ids (that have been assigned in pointer-generator mode), or None (in baseline mode)\n",
        "  Returns:\n",
        "    words: list of words (strings)\n",
        "  \"\"\"\n",
        "  words = []\n",
        "  for i in id_list:\n",
        "    try:\n",
        "      w = vocab.id2word(i) # might be [UNK]\n",
        "    except ValueError as e: # w is OOV\n",
        "      assert source_oovs is not None, \"Error: model produced a word ID that isn't in the vocabulary. This should not happen in baseline (no pointer-generator) mode\"\n",
        "      source_oov_idx = i - vocab.size()\n",
        "      try:\n",
        "        w = source_oovs[source_oov_idx]\n",
        "      except ValueError as e: # i doesn't correspond to an article oov\n",
        "        raise ValueError('Error: model produced word ID %i which corresponds to source OOV %i but this example only has %i source OOVs' % (i, article_oov_idx, len(article_oovs)))\n",
        "    words.append(w)\n",
        "  return ' '.join(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi4_ycSR6qqP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_source_oovs(source):\n",
        "  \"\"\"Returns the article string, highlighting the OOVs by placing __underscores__ around them\"\"\"\n",
        "  unk_token = vocab.word2id('<UNK>')\n",
        "  words = source.split(' ')\n",
        "  words = [(\"__%s__\" % w) if vocab.word2id(w)==unk_token else w for w in words]\n",
        "  out_str = ' '.join(words)\n",
        "  return out_str\n",
        "\n",
        "\n",
        "def show_target_oovs(target, source_oovs):\n",
        "  \"\"\"Returns the abstract string, highlighting the article OOVs with __underscores__.\n",
        "  If a list of article_oovs is provided, non-article OOVs are differentiated like !!__this__!!.\n",
        "  Args:\n",
        "    abstract: string\n",
        "    vocab: Vocabulary object\n",
        "    article_oovs: list of words (strings), or None (in baseline mode)\n",
        "  \"\"\"\n",
        "  unk_token = vocab.word2id('<UNK>')\n",
        "  words = target.split(' ')\n",
        "  new_words = []\n",
        "  for w in words:\n",
        "    if vocab.word2id(w) == unk_token: # w is oov\n",
        "      if source_oovs is None: # baseline mode\n",
        "        new_words.append(\"__%s__\" % w)\n",
        "      else: # pointer-generator mode\n",
        "        if w in source_oovs:\n",
        "          new_words.append(\"__%s__\" % w)\n",
        "        else:\n",
        "          new_words.append(\"!!__%s__!!\" % w)\n",
        "    else: # w is in-vocab word\n",
        "      new_words.append(w)\n",
        "  out_str = ' '.join(new_words)\n",
        "  return out_str"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBLApm5HuKUS",
        "colab_type": "code",
        "outputId": "b6247816-179c-43b3-9192-c6e852291a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(source2ids('this is a weird typo'))\n",
        "print(tokenizer.texts_to_sequences([\"this is a weird typo\"]))\n",
        "print(show_source_oovs(\"this is a weird typo\"))\n",
        "print(show_target_oovs(\"this is a weird typo\",[\"weird\"]))\n",
        "print(outputids2words([18,14,7,20002,20003],[\"weird\",\"typo\"]))"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "([18, 14, 7, 20002, 20003], ['weird', 'typo'])\n",
            "[[18, 14, 7, 1, 1]]\n",
            "this is a __weird__ __typo__\n",
            "this is a __weird__ !!__typo__!!\n",
            "this is a weird typo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Y8qsr2cQ_Sm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "on_pointer = True\n",
        "on_coverage = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0dDtN5jmUlQ",
        "colab_type": "text"
      },
      "source": [
        "Convert text to numeric indicies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKe9LKo7WZnN",
        "colab_type": "code",
        "outputId": "83bb4273-95d9-444d-fcf0-fff84e1182d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "if on_pointer is True:\n",
        "  body_seqs_oov=[source2ids(seq)[0] for seq in body_data]\n",
        "  body_oovs=[source2ids(seq)[1] for seq in body_data]\n",
        "\n",
        "body_seqs=tokenizer.texts_to_sequences(body_data)\n",
        "target_seqs=tokenizer.texts_to_sequences(target_data)\n",
        "\n",
        "print(body_seqs[0])"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5, 337, 6, 8806, 2, 492, 39, 2178, 4, 1263, 2658, 8807, 4549, 648, 371, 587, 274, 12, 416, 13, 45, 278, 4, 2, 41, 12, 93, 4008, 5294, 3, 2002, 346, 1417, 9, 1932, 5, 154, 3, 2, 274, 6, 362, 406, 26, 8311, 479, 1, 81, 3, 1417, 497, 860, 5, 180, 1886, 58, 2178, 783, 4, 1758, 7, 128, 111, 6, 2178, 1417, 310, 2, 2178, 1417, 240, 14, 938, 61, 5, 3186, 2, 79, 3, 519, 1856, 16, 8807, 4549, 2, 4660, 3, 18, 240, 188, 95, 9, 49, 399, 5, 68, 274, 121, 9, 7, 102, 492, 39, 2, 41, 3, 2, 2178, 4, 1263, 2658, 648, 91, 73, 17, 502, 3, 2, 371, 274, 12, 93, 13, 794, 1002, 83, 329, 27, 1554, 44, 165, 37, 27, 316, 5, 19, 3, 371, 274, 2, 8807, 111, 6, 2178, 1417, 9, 3726, 128, 280, 2, 111, 6, 1263, 1417, 9, 69, 4, 18, 65, 1616, 25, 1808, 13, 26, 8311, 479, 1, 81, 3, 1417, 2, 2178, 1417, 240, 14, 3726, 3860, 2446, 27, 1, 188, 7, 34, 6, 99, 1229, 284, 22, 830, 11, 2, 132, 3, 2178, 20, 1263, 2658, 8807, 4549, 648, 389, 382, 5, 169, 3187, 1060, 2, 2658, 8807, 4549, 5, 112, 1886, 5, 209, 2, 2178, 1417, 240, 65, 25, 5591, 61, 6, 620, 2, 79, 3, 519, 1856, 16, 2658, 8807, 4549]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61FYCoAHL1Qq",
        "colab_type": "text"
      },
      "source": [
        "Add start and end tokens to all sequences. Start token index = vocab.size and end token index = vocab.size+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAQioivgL0d7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "body_seqs = [[vocab_size]+seq+[vocab_size+1] for seq in body_seqs]\n",
        "target_seqs = [[vocab_size]+seq+[vocab_size+1] for seq in target_seqs]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dI4drSSmeH9",
        "colab_type": "text"
      },
      "source": [
        "Pad all sequences with zeros up to the maximum sequence length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgghEtRqXDCR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_body = max([len(seq) for seq in body_seqs])\n",
        "max_len_target = max([len(seq) for seq in target_seqs])\n",
        "body_seqs=tf.keras.preprocessing.sequence.pad_sequences(body_seqs, maxlen=max_len_body, padding=\"post\")\n",
        "target_seqs=tf.keras.preprocessing.sequence.pad_sequences(target_seqs, maxlen=max_len_target, padding=\"post\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0iPCVdBmn0b",
        "colab_type": "text"
      },
      "source": [
        "Create a dataset from which batches of a certain size can be extracted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rl-aGPvYU4n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "buffer_size = len(body_seqs)\n",
        "batch_size = 16\n",
        "index = tf.convert_to_tensor(range(buffer_size))\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((body_seqs,target_seqs,index))\n",
        "train_dataset = train_dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg2rZviFl_MA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.bi_gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(\n",
        "            hidden_units,\n",
        "            return_sequences=True,\n",
        "            return_state=True,\n",
        "            recurrent_initializer='glorot_uniform',\n",
        "        ))\n",
        "    def call(self, encoder_input, encoder_states):\n",
        "        # inputs: encoder_input = (batch_size, seq_length)\n",
        "        #         encoder_states = list[(batch_size, hidden_units),(batch_size, hidden_units)]\n",
        "        \n",
        "        # embedding look-up layer\n",
        "        encoder_emb = self.embedding(encoder_input) # (batch_size,seq_length,embedding_dim)\n",
        "        \n",
        "        # encoder_output = (batch_size,seq_length,hidden_units)\n",
        "        # encoder_states = (batch_size,hidden_units)\n",
        "        encoder_output, state_fwd, state_back = self.bi_gru(encoder_emb,initial_state=encoder_states)\n",
        "        encoder_states = [state_fwd,state_back]\n",
        "\n",
        "        return encoder_output, encoder_states"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsySdqmepD5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BahdanauAttention(tf.keras.Model):\n",
        "    def __init__(self, hidden_units,is_coverage=False):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.Wh = tf.keras.layers.Dense(hidden_units) # weight matrix for encoder hidden state\n",
        "        self.Ws = tf.keras.layers.Dense(hidden_units) # weight matrix for decoder state\n",
        "        self.wc = tf.keras.layers.Dense(1) # weight vector for coverage\n",
        "        self.V = tf.keras.layers.Dense(1)\n",
        "        self.coverage = is_coverage\n",
        "        if self.coverage is False:\n",
        "            self.wc.trainable = False\n",
        "        \n",
        "    def call(self, decoder_state, encoder_output,coverage_vector):\n",
        "        # inputs: decoder_state = (batch_size, hidden_units)\n",
        "        #         encoder_output = (batch_size, seq_length, hidden_units)\n",
        "        #         coverage_vector = (batch_size, seq_length)\n",
        "\n",
        "        # expand dimension of decoder state and coverage vector to allow addition\n",
        "        decoder_state = tf.expand_dims(decoder_state, 1) # (batch_size, 1, hidden_units)\n",
        "        coverage_vector = tf.expand_dims(coverage_vector, 1) # (batch_size, 1, seq_length)\n",
        "\n",
        "        # calculate attention scores\n",
        "        # score = (batch_size, length, 1)\n",
        "        score = self.V(tf.nn.tanh(\n",
        "                        self.Wh(encoder_output) +  # (batch_size, length, hidden_units) -> (batch_size, length, attention_units)\n",
        "                        self.Ws(decoder_state) +  # (batch_size, 1, hidden_units) -> (batch_size, 1, attention_units)\n",
        "                        self.wc(coverage_vector) # (batch_size, 1, seq_length) -> (batch_size, 1, 1)\n",
        "                        )) \n",
        "        \n",
        "        attention_weights = tf.nn.softmax(score, axis=1) # (batch_size, seq_length, 1)\n",
        "        # only update coverage vector if coverage is enabled\n",
        "        coverage_vector = tf.squeeze(coverage_vector,1) # (batch_size, seq_length)\n",
        "        if self.coverage is True:\n",
        "          coverage_vector+=tf.squeeze(attention_weights) \n",
        "\n",
        "        context_vector = attention_weights * encoder_output # (batch_size, seq_length, hidden_units)\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1) # (batch_size, hidden_units)\n",
        "\n",
        "        return context_vector, attention_weights, coverage_vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBONK9JFpGFj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_units, is_pointer=False):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.hidden_units = hidden_units\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(\n",
        "            hidden_units,\n",
        "            return_sequences=True,\n",
        "            return_state=True,\n",
        "            recurrent_initializer='glorot_uniform',\n",
        "        )\n",
        "        self.W1 = tf.keras.layers.Dense(hidden_units)\n",
        "        self.W2 = tf.keras.layers.Dense(vocab_size)\n",
        "        self.pointer = is_pointer\n",
        "        # Pointer Generator\n",
        "        # wh = tf.keras.layers.Dense(1)\n",
        "        # ws = tf.keras.layers.Dense(1)\n",
        "        # wx = tf.keras.layers.Dense(1)\n",
        "        if is_pointer is True:\n",
        "          self.w_gen = tf.keras.layers.Dense(1)\n",
        "        \n",
        "    def call(self, decoder_input, decoder_state, encoder_output,context_vector):\n",
        "        # inputs: decoder_input = (batch_size, 1)\n",
        "        #         decoder_state = (batch_size, hidden_units)\n",
        "        #         encoder_output = (batch_size,seq_length, hidden_units)\n",
        "        #         coverage_vector = (batch_size,seq_length)\n",
        "        # embedding look-up layer\n",
        "        decoder_emb = self.embedding(decoder_input) # (batch_size, seq_length, hidden_units)\n",
        "\n",
        "        # decoder_output = (batch_size,seq_length,hidden_units)\n",
        "        # decoder_state = (batch_size,hidden_units)\n",
        "        decoder_output , decoder_state = self.gru(decoder_emb,initial_state=decoder_state)\n",
        "\n",
        "        # concatenate context vector and decoder state \n",
        "        concat_vector = tf.concat([context_vector,decoder_state], axis=-1)\n",
        "        # reshape to 1d array\n",
        "        concat_vector = tf.reshape(concat_vector, (-1, concat_vector.shape[1]))\n",
        "        # create vocabulary distribution\n",
        "        p_vocab = tf.nn.softmax(self.W2(self.W1(concat_vector)))\n",
        "        p_gen = None\n",
        "        if self.pointer is True:\n",
        "          # calculate p_gen\n",
        "          x_gen = tf.concat([context_vector,decoder_state,tf.squeeze(decoder_emb,1)], axis = -1)\n",
        "          p_gen = tf.nn.sigmoid(self.w_gen(x_gen))\n",
        "        return p_vocab, decoder_state, p_gen"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSxdAOQ5EwIO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_final_distribution(update, p_gen, p_vocab, attention_weights, max_oovs, batch_size = batch_size):\n",
        "  if on_pointer:\n",
        "    # Get the weighted probabiity\n",
        "    p_gen = tf.linalg.diag(tf.squeeze(p_gen,-1))\n",
        "    p_vocab_f = p_gen@p_vocab\n",
        "    len_seq = tf.shape(attention_weights)[1]\n",
        "    attention_f = (tf.linalg.eye(batch_size)-p_gen)@tf.squeeze(attention_weights,-1)\n",
        "    # Get the extended-vocab probability distribution\n",
        "    extended_size = vocab.size() + max_oovs # the maximum (over the batch) size of the extended vocabulary\n",
        "    extension = tf.zeros((batch_size, max_oovs), tf.float32)\n",
        "    batch_nums = tf.expand_dims(tf.range(0, limit=batch_size),1)\n",
        "    batch_nums = tf.tile(batch_nums,[1,len_seq])\n",
        "    indices = tf.stack((batch_nums, update), axis=2)\n",
        "    p_vocab_f = tf.concat([p_vocab_f,extension], axis = -1)\n",
        "    # Add the attention to the probability\n",
        "    p_vocab = tf.tensor_scatter_nd_add(p_vocab_f,indices,attention_f)\n",
        "    # Take log probability\n",
        "  p_vocab = tf.math.log(p_vocab)\n",
        "  return p_vocab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9udcRhiTdREd",
        "colab_type": "text"
      },
      "source": [
        "Initialize encoder and decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIdpMfncpK5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "embedding_dim = 128\n",
        "hidden_units = 128\n",
        "encoder = Encoder(vocab.size(), embedding_dim, hidden_units) # +2 on due to start and end tokens\n",
        "attention = BahdanauAttention(hidden_units,is_coverage=on_coverage)\n",
        "decoder = Decoder(vocab.size(), embedding_dim, hidden_units, is_pointer = on_pointer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlPleBGNkdLQ",
        "colab_type": "text"
      },
      "source": [
        "Run one batch through the model in order to initialize model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsM9QUZpkaMu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input_init , decoder_target, index = next(iter(train_dataset))\n",
        "encoder_init_states = [tf.zeros((batch_size, encoder.hidden_units)) for i in range(2)]\n",
        "if on_pointer:\n",
        "  max_oovs = max([len(body_oovs[i]) for i in index])\n",
        "else:\n",
        "  max_oovs = 0\n",
        "\n",
        "encoder_output, encoder_states = encoder(encoder_input_init,encoder_init_states)\n",
        "decoder_state = encoder_states[0] \n",
        "coverage_vector = tf.zeros((16,encoder_input_init.shape[1]))\n",
        "decoder_input_t = decoder_target[:,0]\n",
        "context_vector, attention_weights, coverage_vector = attention(decoder_state, encoder_output,coverage_vector)\n",
        "p_vocab,decoder_state,p_gen = decoder(tf.expand_dims(decoder_input_t,1),decoder_state,encoder_output,context_vector)\n",
        "p_vocab = get_final_distribution(encoder_input_init, p_gen, p_vocab, attention_weights, max_oovs, batch_size)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2kcLbzOhrlt",
        "colab_type": "text"
      },
      "source": [
        "Load pretrained weights if needed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2180O-yPUEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model_save_path = \"\"\n",
        "# encoder_save_name = \"encoder_weights30.h5\"\n",
        "# decoder_save_name = \"decoder_weights30.h5\"\n",
        "# attention_save_name = \"attention_30epochs.h5\"\n",
        "# encoder.load_weights(os.path.join(model_save_path,encoder_save_name))\n",
        "# decoder.load_weight(os.path.join(model_save_path,decoder_save_name))\n",
        "# attention.load_weights(os.path.join(model_save_path,attention_save_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pC567knspwSz",
        "colab_type": "text"
      },
      "source": [
        "Define optimizer and loss function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVNa8U62pvUO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "def nll_loss(p_vocab,target):\n",
        "    # apply a mask such that pad zeros do not affect the loss\n",
        "    mask = tf.math.logical_not(tf.math.equal(target, 0))\n",
        "    loss = -p_vocab\n",
        "    mask = tf.cast(mask, dtype=loss.dtype)\n",
        "    loss *= mask  \n",
        "    return loss\n",
        "\n",
        "def coverage_loss(attention_weights,coverage_vector,target):\n",
        "    mask = tf.math.logical_not(tf.math.equal(target, 0))\n",
        "    coverage_vector = tf.expand_dims(coverage_vector,axis=2)\n",
        "    ct_min = tf.reduce_min(tf.concat([attention_weights,coverage_vector],axis=2),axis=2)\n",
        "    cov_loss = tf.reduce_sum(ct_min,axis=1)\n",
        "    mask = tf.cast(mask, dtype=cov_loss.dtype)\n",
        "    cov_loss *= mask\n",
        "    return cov_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctb2Zl8RuxnA",
        "colab_type": "text"
      },
      "source": [
        "Define a function for performing one training step (one batch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee51wXkDkfcO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(encoder_input, decoder_target, index):\n",
        "    \"\"\"Function which performs one training step (batch)\"\"\"\n",
        "    loss = tf.zeros(batch_size)\n",
        "    lambda_cov = 1\n",
        "    if on_pointer:\n",
        "      max_oovs = max([len(body_oovs[i]) for i in index])\n",
        "    else:\n",
        "      max_oovs = 0\n",
        "    with tf.GradientTape() as tape:\n",
        "        # run body_sequence input through encoder\n",
        "        encoder_init_states = [tf.zeros((batch_size, encoder.hidden_units)) for i in range(2)]\n",
        "        encoder_output, encoder_states = encoder(encoder_input,encoder_init_states)\n",
        "        # initialize decoder with encoder forward state\n",
        "        decoder_state = encoder_states[0] # !!!interpolate between forward and backward instead!!!\n",
        "        coverage_vector = tf.zeros((16,encoder_input.shape[1]))\n",
        "        # loop over each word in target sequence\n",
        "        for t in range(decoder_target.shape[1]-1):\n",
        "            # run decoder input through decoder and generate vocabulary distribution\n",
        "            decoder_input_t = decoder_target[:,t]\n",
        "            decoder_target_t = decoder_target[:,t+1]\n",
        "            # get attention scores\n",
        "            context_vector, attention_weights, coverage_vector = attention(decoder_state, encoder_output,coverage_vector)\n",
        "            # get vocabulary distribution for each batch at time t\n",
        "            p_vocab,decoder_state,p_gen = decoder(tf.expand_dims(decoder_input_t,1),decoder_state,encoder_output,context_vector)\n",
        "            p_vocab = get_final_distribution(encoder_input, p_gen, p_vocab, attention_weights, max_oovs, batch_size)\n",
        "            # for each batch get the probability of the target word at time t+1\n",
        "            p_vocab_list = []\n",
        "            for i in range(len(decoder_target_t)):\n",
        "                p_vocab_list.append(p_vocab[i,decoder_target_t[i]])\n",
        "            p_vocab_target = tf.stack(p_vocab_list)\n",
        "            # calculate the loss at each time step t and add to current loss\n",
        "            loss += nll_loss(p_vocab_target,decoder_target_t) + lambda_cov*coverage_loss(attention_weights,coverage_vector,decoder_target_t)\n",
        "\n",
        "        # get the non-padded length of each sequence in the batch\n",
        "        seq_len_mask = tf.cast(tf.math.logical_not(tf.math.equal(decoder_target, 0)),tf.float32)\n",
        "        batch_seq_len = tf.reduce_sum(seq_len_mask,axis=1)\n",
        "\n",
        "        # get batch loss by dividing the loss of each batch by the target sequence length and mean\n",
        "        batch_loss = tf.reduce_mean(loss/batch_seq_len)\n",
        "\n",
        "    # update trainable variables\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(batch_loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "    \n",
        "    return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XH_-kaqadXXo",
        "colab_type": "text"
      },
      "source": [
        "Training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T56FA7YkX2A_",
        "colab_type": "code",
        "outputId": "521dc45a-bda2-4ed9-9970-d86bad26d5c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227,
          "referenced_widgets": [
            "49beebd721e3417ca0ed1efcdad3a73c",
            "a0887b2d69444f76ab43866b9fadfc52",
            "4dea8893e65f409ab475a547ce4fc63d",
            "35ef93f265494c92ae1f288030ddc372",
            "e6360e3db831469bbe78e30c7b52227d",
            "42730b402ca64cc7b02d578e0af05662",
            "35c18a134a4440fbab9c06dec4c52772",
            "ceb40ea7c4904379b0f4ab928fabbf24",
            "222ebdfa9e35453aba6e2d23c447a1b0",
            "7b4cb2751bb64f45b17cda954c88bbed",
            "4c6fb04b5adf4c58b7afcdf6c504ea62",
            "df604f8a21c84ac8b2d23ccb88ee5878",
            "954926dec0864ab7b0e868a6c221763d",
            "29a15376ad4f4f40bf7a975dd40af382",
            "0049272fffa544d7bb2a7f65b2b1f368",
            "a27cbc71c5564edab2ccd458eff6ee55",
            "1456ba6aae744287a0397e183bed7ece",
            "6599d11db78749cca023e1f2ac1f48a5",
            "74261db027f141bdb5619c5a0dfc2a3f",
            "0dc84f675f2a4f3fa8ef28068d81a302",
            "1c33a01277e748ff9c917cc306a13cbb",
            "7adaf5b1c09544f09e04a532d2c45a89",
            "491f030c8f6c48eba645e477969f0981",
            "8f1e4894ad8c487e815ab336f1747fc8",
            "db6e4e341e9243828bb750db067bb681",
            "d5209897a55549e7903b313148b0a01d",
            "060eec12dc7044b9b405adeebfcf154b",
            "e13bb4b7823a4dc0bc291913866fbaaa",
            "50f0486fdaef49e7800fd45aa3d39882",
            "6c1a03e7502a4fdf8a8f33505ef34bcd",
            "c8fee3ab5cc148679a2d894e1a7bbb39",
            "e0ac14d8b93d479894e06c13bb342776",
            "b06a062dcc6d414c8111cdf8f7bbaa4d",
            "1adfa4776e93499ea63346a33a6c1481",
            "4057ebcc415244e084af1fd16a5b9ffc",
            "55b400f46a594318af33cbec9ba93cd3",
            "4b43d9adc04847698bd21363ed84e165",
            "d1bf768ab12b49439255ea2b0e0ef6e9",
            "972f114dc0214127a250853d4ba73ef3",
            "24ad41d2518e4287970b159f83c9cb71",
            "b5411c13cbc043b8a7eb606a92ee8058",
            "50259c9b525d4fe28c95b3abbd43d48d",
            "9428fd4bd0ca457aa83af938b7bfe107",
            "d7ef96b8fb674acda91e765f87eb15c6",
            "2b6090dbebe24682bcec05fc6b270339",
            "6481a40e13e4486689f4138121635be3",
            "15684a1d52c24a62bb053f04495b4b2c",
            "52d386ee5b994b49aa092eeb0a0b22c0"
          ]
        }
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "epoch_loss = tf.keras.metrics.Mean()\n",
        "with tqdm(total=epochs) as epoch_progress:\n",
        "    for epoch in range(epochs):\n",
        "        epoch_loss.reset_states()\n",
        "\n",
        "        with tqdm(total=len(body_seqs) // batch_size) as batch_progress:\n",
        "            for batch, (encoder_input, decoder_target, index) in enumerate(train_dataset):\n",
        "                batch_loss = train_step(encoder_input, decoder_target, index)\n",
        "                epoch_loss(batch_loss)\n",
        "                \n",
        "                if (batch % 10) == 0:\n",
        "                    batch_progress.set_description(f'Epoch {epoch + 1}')\n",
        "                    batch_progress.set_postfix(Batch=batch, Loss=batch_loss.numpy())\n",
        "                batch_progress.update()\n",
        "        \n",
        "        epoch_progress.set_description(f'Epoch {epoch + 1}')\n",
        "        epoch_progress.set_postfix(Loss=epoch_loss.result().numpy())\n",
        "        epoch_progress.update()"
      ],
      "execution_count": 204,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "49beebd721e3417ca0ed1efcdad3a73c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "222ebdfa9e35453aba6e2d23c447a1b0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=427), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1456ba6aae744287a0397e183bed7ece",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=427), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db6e4e341e9243828bb750db067bb681",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=427), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b06a062dcc6d414c8111cdf8f7bbaa4d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=427), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5411c13cbc043b8a7eb606a92ee8058",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=427), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZCMatONESEz",
        "colab_type": "text"
      },
      "source": [
        "Evaluate model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zh_Vi0NEi2A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def greedy_search(encoder_input,max_sum_len = 20):\n",
        "    \"\"\"Function which returns a summary by always picking the highest probability option conditioned on the previous word\"\"\"\n",
        "    # run body_sequence through encoder\n",
        "    encoder_init_states = [tf.zeros((1, encoder.hidden_units)) for i in range(2)]\n",
        "    encoder_output, encoder_states = encoder(encoder_input,encoder_init_states)\n",
        "    # initialize decoder with encoder forward state\n",
        "    decoder_state = encoder_states[0]\n",
        "\n",
        "    decoder_input_t = tf.ones(1)*tokenizer.num_words # initialize with start token\n",
        "    summary = [tokenizer.num_words]\n",
        "    coverage_vector = tf.zeros((1,encoder_input.shape[1]))\n",
        "    while decoder_input_t[0].numpy()!=(tokenizer.num_words+1) and len(summary)<max_sum_len: # as long as decoder input is different from end token continue\n",
        "        context_vector, attention_weights, coverage_vector = attention(decoder_state, encoder_output,coverage_vector)\n",
        "        p_vocab, decoder_state, p_gen = decoder(tf.expand_dims(decoder_input_t,1),decoder_state,encoder_output,context_vector)\n",
        "        p_vocab = get_final_distribution(encoder_input, p_gen, p_vocab, attention_weights, max_oovs,1)\n",
        "        decoder_input_t = tf.argmax(p_vocab,axis=1) \n",
        "        decoder_word_idx = int(decoder_input_t[0].numpy())\n",
        "        summary.append(decoder_word_idx)\n",
        "    return summary"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yWZKItF6bzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def best_k_candidates(prev,k,encoder_output):\n",
        "    # use decoder to generate probability over vocabulary for the next token\n",
        "    decoder_input_t = tf.expand_dims(tf.expand_dims(prev[0][-1],0),1)\n",
        "    context_vector, attention_weights, coverage_vector = attention(prev[2][0], encoder_output,prev[2][1])\n",
        "    p_vocab, decoder_state,p_gen = decoder(decoder_input_t, prev[2][0],encoder_output,context_vector)\n",
        "    p_vocab = get_final_distribution(encoder_input, p_gen, p_vocab, attention_weights, max_oovs, 1)    \n",
        "    # sort the hypothesis by probability\n",
        "    idx = tf.argsort(p_vocab, direction='DESCENDING')  # sorted indices\n",
        "    ranks = tf.argsort(idx, direction='ASCENDING')  # ranks\n",
        "    filter_k = ranks < k # return True in the position with rank 1, 2, ..., k\n",
        "    # just for convenience, change to numpy\n",
        "    size = vocab.size()+max_oovs \n",
        "    p_vocab = p_vocab.numpy().reshape(-1)\n",
        "    filter_k = filter_k.numpy().reshape(-1)\n",
        "    # get the best hypothesis\n",
        "    best_k_candidates = [ [prev[0]+[x],p_vocab[x]+prev[1],[decoder_state,coverage_vector,attention_weights,max_oovs,prev[2][4]]] for x in range(size) if filter_k[x] ]\n",
        "    return best_k_candidates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1w7QDpxS7KdO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def best_k_of_k2(best_k,k,completed,encoder_output):\n",
        "    results = []\n",
        "    # for each previous hypothesis, find k best hypothesis induced from it. THis will result in k^2 hypothesis\n",
        "    for hypo in best_k:\n",
        "      results = results + best_k_candidates(hypo, k, encoder_output)\n",
        "    # sort the list and extract k best hypothesis\n",
        "    results = sorted(results,key = lambda x: x[1],reverse= True)[0:k]\n",
        "    # if there is a completed hypothesis (end token generated), transfer it to completed set and decrease the beam size\n",
        "    for result in results:  \n",
        "      if result[0][-1] == vocab.word2id('<\\s>'):\n",
        "        k-=1\n",
        "        results.remove(result)\n",
        "        completed += [result]\n",
        "    return results,k,completed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sVihBTAE7ekD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def beam_search(encoder_input, max_sum_len = 20, beam_width = 5):\n",
        "      # run body_sequence input through encoder\n",
        "      encoder_init_states = [tf.zeros((1, encoder.hidden_units)) for i in range(2)]\n",
        "      encoder_output, encoder_states = encoder(encoder_input,encoder_init_states)\n",
        "\n",
        "      # initialize decoder with encoder forward states\n",
        "      decoder_states = encoder_states[0]\n",
        "      coverage_vector = tf.zeros((1,encoder_input.shape[1]))\n",
        "      # initialize the hypothesis: [sequence <s>, log probability 0, decoder states]\n",
        "      prev = [[vocab_size],0,[decoder_states,coverage_vector, attention_weights, max_oovs, encoder_input]]\n",
        "      # get the beam size and create a list to store completed hypothesis \n",
        "      k = beam_width\n",
        "      completed = []\n",
        "      # get k best first token\n",
        "      best_k = best_k_candidates(prev,k,encoder_output)\n",
        "\n",
        "      # use beam search for max_sum_len (maximum length) steps\n",
        "      for i in range(max_sum_len):\n",
        "        # get k best hypothesis when adding a new token\n",
        "        best_k,k,completed = best_k_of_k2(best_k,k,completed,encoder_output)\n",
        "        # stop when there are enough completed hypothesis\n",
        "        if len(completed) == k:\n",
        "          break \n",
        "      \n",
        "      # when there are no completed hypothesis, take 5 last hypothesis as the final candidates\n",
        "      if len(completed) == 0:\n",
        "        completed = best_k\n",
        "      # normalized the hypothesis probability by the length of hypothesis\n",
        "      for hypo in completed:\n",
        "        hypo[1]/=len(hypo[0])\n",
        "        hypo = [hypo[1],hypo[2]]   \n",
        "      # sort the hypothesis by normalized probability and choose the best one       \n",
        "      best_k = sorted(completed,key=lambda x: x[1],reverse=True)[0][0]\n",
        "      return best_k"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lj9oGQo9w3GB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_save_name = \"encoder_30epochs.h5\"\n",
        "decoder_save_name = \"decoder_30epochs.h5\"\n",
        "attention_save_name = \"attention_30epochs.h5\"\n",
        "encoder.save_weights(encoder_save_name)\n",
        "decoder.save_weights(decoder_save_name)\n",
        "attention.save_weights(attention_save_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktHV__vixcE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# files.download(attention_save_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7XqpsXBu_Bn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input, decoder_target, index = next(iter(train_dataset))\n",
        "if on_pointer:\n",
        "  max_oovs = max([len(body_oovs[i]) for i in index])\n",
        "else:\n",
        "  max_oovs = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShWnw-PzEai2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_input = tf.expand_dims(encoder_input[0,:],0)\n",
        "summary_greedy = greedy_search(encoder_input)\n",
        "summary_beam = beam_search(encoder_input)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEjMdLyQEdUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_summary = [d for d in decoder_target.numpy()[0] if d!=0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJmkncscEfr1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "4c2d0194-6a33-4814-be50-ff056a1b6cb0"
      },
      "source": [
        "print(\"Generated by greedy search:\"+ outputids2words(summary_greedy,body_oovs[index[0]]))\n",
        "print(\"Generated by bream search:\"+ outputids2words(summary_beam,body_oovs[index[0]]))\n",
        "print(\"Target:\"+\" \".join([tokenizer.index_word[idx] for idx in target_summary]))"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generated by greedy search:<s> 91 granulosus in the granulosus of the granulosus <\\s>\n",
            "Generated by bream search:<s> 91 development of the granulosus of the granulosus <\\s>\n",
            "Target:<s> the genome of the hydatid <UNK> echinococcus granulosus <\\s>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}